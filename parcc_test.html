<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>The PARCC Test</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="site_libs/highlight/default.css"
      type="text/css" />
<script src="site_libs/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="css\style.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 60px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 65px;
  margin-top: -65px;
}

.section h2 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h3 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h4 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h5 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h6 {
  padding-top: 65px;
  margin-top: -65px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.9em;
  padding-left: 5px;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Ryan G Knight</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Projects
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="parcc.html">Understanding PARCC Scores</a>
    </li>
    <li>
      <a href="microenterprises.html">Micro Enterprise Growth</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/rgknight">
    <span class="fa fa-github"></span>
     
  </a>
</li>
<li>
  <a href="https://twitter.com/rgknight">
    <span class="fa fa-twitter"></span>
     
  </a>
</li>
<li>
  <a href="https://medium.com/@rgknight">
    <span class="fa fa-medium"></span>
     
  </a>
</li>
<li>
  <a href="https://www.linkedin.com/in/ryan-knight-98179140">
    <span class="fa fa-linkedin"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">The PARCC Test</h1>

</div>


<p>This is Part 2 of my Understanding PARCC series. <a href="parcc.html">Part 1</a> covered the practical implications of measurement error. Part 2 is an introduction to the PARCC test.</p>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>PARCC attempts to measure performance across the Common Core State Standards for a given grade level. PARCC’s high level goal is to provide a valid estimate of college and career readiness.</p>
<p>PARCC administers multiple test forms within a grade level and content area. That is, students in the same grade level are seeing different items when they take PARCC. Despite the best efforts of PARCC, the test forms have some variation in difficulty. Therefore, PARCC cannot report the raw % correct – it would mean something different depending on which test form the student had. If the student had a test form that was on the easier side, the raw % correct would overstate their performance.</p>
<p>To correct for these differences, and to make scores comparable across years, PARCC reports results using a scaled score, which ranges from 650 to 850. The 650 to 850 scale has no inherent meaning; it’s just what PARCC chose. They could have chosen 3 to 10,000 just as easily.</p>
<p>Scaled scores are grouped into 5 performance levels. The cut score for performance levels varies slightly by grade level and content area.</p>
<p>Example 2015 cut scores</p>
<table style="width:76%;">
<colgroup>
<col width="11%" />
<col width="23%" />
<col width="20%" />
<col width="20%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Level</th>
<th align="center">Cut.Score.Rule</th>
<th align="center">Grade.6.Math</th>
<th align="center">Grade.7.Math</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Level 1</td>
<td align="center">Always 650</td>
<td align="center">650</td>
<td align="center">650</td>
</tr>
<tr class="even">
<td align="center">Level 2</td>
<td align="center">Always 700</td>
<td align="center">700</td>
<td align="center">700</td>
</tr>
<tr class="odd">
<td align="center">Level 3</td>
<td align="center">Always 725</td>
<td align="center">725</td>
<td align="center">725</td>
</tr>
<tr class="even">
<td align="center">Level 4</td>
<td align="center">Always 750</td>
<td align="center">750</td>
<td align="center">750</td>
</tr>
<tr class="odd">
<td align="center">Level 5</td>
<td align="center">Derived</td>
<td align="center">788</td>
<td align="center">786</td>
</tr>
</tbody>
</table>
<p>This means that a student scoring 787 in 6th grade and 787 again in 7th grade would be considered Level 4 in 6th grade and Level 5 in 7th grade. Thus, while scaled scores are very similar across grades and content, there are some differences in the meaning of a scaled score across grade levels.</p>
</div>
<div id="test-forms" class="section level2">
<h2>Test Forms</h2>
<p>PARCC repeats certain groups of items across test forms and across years. This is done to improve the ability to help build a consistent comparison across test forms and across years. PARCC estimates that 60-68% of students in ELA and 60-70% of students in Math would be classified at the same level if they took the same test using different test forms. That is, roughly 1 in 3 students would be classified at a different level if they had received a different test form and about 10% of students would move in/out of Meeting Expectations. Measuring student ability is hard.</p>
</div>
<div id="item-design-and-scoring" class="section level2">
<h2>Item Design and Scoring</h2>
<p>PARCC designs items through a process of internal drafting with several layers of expert review.</p>
<p>All items are tested with students prior to being used for scoring purposes. Some items were tested in optional field tests and others were integrated into earlier administrations as unscored field test items. PARCC cuts items based on the field test, and also cuts some live items based a review of item statistics.</p>
<p>Constructed response items were scored by a team of trained human scorers. The scorers needed to correctly score an example set of responses (after receiving training) within an acceptable range of tolerance to be selected as a scorer. 10% of items were rescored, either by humans or sometimes by a robot.</p>
<p>The rescoring did not affect student scores – PARCC always used the original score, never the rescore. The rescore was only to monitor scorer ability and provide information about item reliability. Scorers with rescoring metrics below certain thresholds received additional training.</p>
</div>
<div id="item-statistics" class="section level2">
<h2>Item statistics</h2>
<p>PARCC calculated various “classical” item statistics to assist in their scoring process, build their knowledge bank about items, and inform future item development.</p>
<p>PARCC also used this review to identify bad items that should be removed from the scaled score calculation. The image below shows the technical criteria for removing items. In addition to these strict rules, PARCC removed some items because of “item performance, technical scoring issues, content concerns, multiple correct answers, or no correct answers”. In grades 3-8, very few items were excluded, usually zero or one. PARCC sometimes used a special model for certain items instead of throwing them out when the standard model wasn’t a good fit.</p>
<blockquote>
<ol style="list-style-type: decimal">
<li>A weighted polyseris correlation less than 0.0</li>
<li>An average item score of 0.0</li>
<li>100% of the students have the same item score, such as:</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>100% omitted the item,</li>
<li>100% received the same score</li>
<li>100% of the responses were at the same score after collapsing score categories due to low frequencies</li>
<li>100% of the responses were not presented or reached</li>
</ol>
<ol start="4" style="list-style-type: decimal">
<li>Insufficient sample sizes for the seleted IRT model combinations (i.e., 300 for the 2PL/GPC).</li>
<li>High omit rates (i.e., greater than 50%) on one or more forms (usually an indication that an item may not be functioning correctly on all forms)</li>
</ol>
</blockquote>
</div>
<div id="percent-correct-on-parcc" class="section level2">
<h2>Percent Correct on PARCC</h2>
<p>Interestingly, the item statistics tables in the technical report include the overall average % correct on PARCC. Unfortunately, the % correct for the 2016 administration is not yet available, but the table below shows the average % correct on PARCC in 2015.</p>
<table style="width:69%;">
<caption>Average Correct on PARCC Paper Based Tests in 2015</caption>
<colgroup>
<col width="11%" />
<col width="13%" />
<col width="13%" />
<col width="15%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Grade</th>
<th align="center">ELA PBA</th>
<th align="center">ELA EOY</th>
<th align="center">Math PBA</th>
<th align="center">Math EOY</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">3</td>
<td align="center">0.45</td>
<td align="center">0.38</td>
<td align="center">0.42</td>
<td align="center">0.50</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="center">0.44</td>
<td align="center">0.41</td>
<td align="center">0.47</td>
<td align="center">0.50</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="center">0.45</td>
<td align="center">0.38</td>
<td align="center">0.38</td>
<td align="center">0.48</td>
</tr>
<tr class="even">
<td align="center">6</td>
<td align="center">0.47</td>
<td align="center">0.44</td>
<td align="center">0.40</td>
<td align="center">0.39</td>
</tr>
<tr class="odd">
<td align="center">7</td>
<td align="center">0.45</td>
<td align="center">0.49</td>
<td align="center">0.35</td>
<td align="center">0.35</td>
</tr>
<tr class="even">
<td align="center">8</td>
<td align="center">0.49</td>
<td align="center">0.45</td>
<td align="center">0.31</td>
<td align="center">0.32</td>
</tr>
</tbody>
</table>
<p>Notice that:</p>
<div id="the-average-correct-is-low" class="section level3">
<h3>The average % correct is “low”</h3>
<p>The most common interim assessments typically have a much higher percent correct. A school could likely calibrate where their students fall relative to the population of PARCC test takers, and use this as a very rough benchmark of what PARCC level rigor means for their interim assessments.</p>
</div>
<div id="one-of-the-reasons-to-scale-scores-is-to-avoid-making-people-feel-sad." class="section level3">
<h3>One of the reasons to scale scores is to avoid making people feel sad.</h3>
<p>It would not do for parents to get reports saying that their students got 35% correct on PARCC. If you are aiming for PARCC rigor on your interim assessments, you should consider scaling it such that students don’t feel bad about a score of 45% correct if the PARCC average was 32% correct.</p>
</div>
<div id="parcc-probably-missed-their-intended-average-percent-correct." class="section level3">
<h3>PARCC probably missed their intended average percent correct.</h3>
<p>PARCC tried to have a range of item difficulty within a test. I would guess their intended range was evenly distributed around 0.5, so they would prefer a test-level average of 0.5. These scores are rather different from 0.5. Measuring student ability is hard.</p>
<a href="parcc_irt.html">
<button type="button" class="btn btn-primary">
Continue to Part 3: Item Response Theory
</button>
<p></a></p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
